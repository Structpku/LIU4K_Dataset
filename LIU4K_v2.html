<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<!-- saved from url=(0039)https://flyywh.github.io/LIU4K_Website/ -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="language" content="english">
<title> Large-scale Ideal Ultra high definition 4K (LIU4K) Dataset </title>
<link rel="stylesheet" type="text/css" href="./LIU4K/project.css">
<script type="text/javascript" src="./LIU4K/MathJax.js.下载">
</script>
</head>

<body data-gr-c-s-loaded="true">
<div id="main">
  
	<div class="content"><br>
		<h1>Large-scale Ideal Ultra high definition 4K Version 2 (LIU4K-v2) Dataset</h1>
		<div class="authors">
		
        	<div class="author">
				 <a href="https://structpku.github.io/LIU4K_Dataset/LIU4K_v2.html" style="text-decoration: none">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
			</div>
			<!--<div class="author">
				 Jiaying Liu
			</div>  
			<div class="author">
				 Dong Liu
			</div>  
			<div class="author">
				 Wenhan Yang
			</div>  
			<div class="author">
				 Sifeng Xia
			</div>  
			<div class="author">
				 Xiaoshuai Zhang
			</div>    
			<div class="author">
				 Yuanying Dai
			</div> -->
			
		</div>
		<br>

		<div class="Abstract sec">
			<h2>Dataset Superiorities</h2>
			<div class="desp">
				<p style="text-align:justify">
                LIU4K-v2 has several unprecedented superiorities as follows,
                <ul>
                <li>High-resolution definition.</li> Compared to previous
datasets, the resolutions of the images in our dataset are at least 3K, most of which belong to 4K-6K, larger than those in previous datasets, which
offers abundant materials for testing and evaluating the
performance in 4K/8K display devices.
                <li>Large-scale.</li> Our dataset is large-scale. Our dataset includes 1600 high-resolution training images and 400 high-resolution validation images, which are much more than those in previous datasets. Thus, training and evaluation based on LIU4K are more comprehensive and balanced.
                <li>Diversified and complex contents.</li> Our dataset includes very diversified kinds of backgrounds and objects and also is diverse and complex in low-level signal distribution.
                <li>High visual quality.</li> Due to its high high-resolution definition and the diversified and complex contents, images in our LIU4K dataset has high visual qualtiy.</ul></p>
                </div>
            <h2>Dataset Overview</h2>
			<div align="center" id="overview">
		  		<img src="./LIU4K/overviewc.png" width="100%">
		  		<p style="text-align: center">Figure. 1. Example training set images sampled from LIU4K-v2.
		</p></div>
		  	<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:5px 15px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:0px 0px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}
.tg .tg-s6z2{text-align:center}
</style>
	
</div>

		<div class="download sec">
			<h2>Download</h2>
			<div>
				
		<li><strong>Datasets</strong>
		<br> Baiduyun: <a href="https://pan.baidu.com/s/1pBL8B6fW6SWshG_6voBBdQ">Train</a> (extracted code: avzb), <a href="https://pan.baidu.com/s/1r5F8HyZ5Qdke8xa7Uv7Pfw">Validation</a> (extracted code: bta6)
		<br> PKU Drive: <a href="https://disk.pku.edu.cn/#/link/A24FA10D6DF59D5AD9F53162698F1E7B">Train</a>, <a href="https://disk.pku.edu.cn/#/link/6D3C0C9B995B65A62A313FE2DDC76715">Validation</a>
                <br><I>All the images are collected fom the Internet, and these images are published under the CC0 License (https://creativecommons.org/share-your-work/public-domain/cc0/). This means basically you can use these images for any purpose. Since the images are collected by us, we ask you to kindly cite the following paper if you are using this dataset.</I>
                </li>
		<br>
                </div>
		</div>

	  <div class="citation sec">
			<h2>Citation</h2>
			<p class="bibtex">@inproceedings{Liu4K, 
&nbsp;&nbsp; author={J. Liu and D. Liu and W. Yang and S. Xia and X. Zhang and Y. Dai}, 
&nbsp;&nbsp; booktitle={arXiv}, 
&nbsp;&nbsp; title={A Comprehensive Benchmark for Single Image Compression Artifacts Reduction}, 
&nbsp;&nbsp; year={2019}, 
&nbsp;&nbsp; }
			</p>
	  </div>

<!-- 		<div class="experiments sec">
			<h2>Additional Results</h2>
			<div id="images">
				<h3>Action Detection Performance</h3>
				<div align="center" id="table">
					<p>Table 1. F 1−Score on OAD dataset</p>
					<img src='OAD/figures/OAD_table.png' width='50%' >
				</div>
			</div>
		</div>
		<br></br> -->


<div class="citation sec">
    <h2>&nbsp;</h2>
    </div>
  </div>
</div>



</body></html>
